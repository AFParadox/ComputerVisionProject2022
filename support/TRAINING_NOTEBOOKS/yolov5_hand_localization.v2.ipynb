{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tQkOSTy1BL9T"
   },
   "source": [
    "# Hand localization model training with YOLOv5\n",
    "In this notebook we will generate a model for the hand recognition and localization task using YOLOv5 and train it.\n",
    "The procedure is divided into steps:\n",
    "1) Manage dependencies and main YOLOv5 files\n",
    "2) Download and extract dataset\n",
    "3) Check on from some random samples that conversion is good\n",
    "4) Last steps\n",
    "5) Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y3DEdZTBBL9V"
   },
   "source": [
    "### 1) Download YOLO and import necessary dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-07-28T08:57:55.158429Z",
     "iopub.status.busy": "2022-07-28T08:57:55.157527Z",
     "iopub.status.idle": "2022-07-28T08:58:09.962903Z",
     "shell.execute_reply": "2022-07-28T08:58:09.961836Z",
     "shell.execute_reply.started": "2022-07-28T08:57:55.158314Z"
    },
    "id": "oEBjAxSDBL9X",
    "outputId": "a9d226bc-ee98-4d9c-cc68-28ea51f00d64"
   },
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "import random\n",
    "if not os.path.isdir('yolov5'):\n",
    "    os.system('git clone https://github.com/ultralytics/yolov5')\n",
    "\n",
    "# install and import yolov5 dependencies\n",
    "!pip install -qr yolov5/requirements.txt\n",
    "import torch, random\n",
    "import numpy as np\n",
    "from IPython.display import Image, clear_output\n",
    "\n",
    "print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")\n",
    "\n",
    "# import dependencies to extract dataset\n",
    "import requests, tarfile, glob\n",
    "\n",
    "# import & install dependencies needed to convert dataset label format to yolov5\n",
    "!apt-get install libmagic-dev\n",
    "!pip install python-magic\n",
    "import magic, re, scipy.io\n",
    "\n",
    "# import libs to verify conversion in step 4\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G-svugIyBL9Y"
   },
   "source": [
    "### 2) Download and extract dataset\n",
    "We now check for the presence of the three datasets, if the program doesn't find them then it will procede to download them.\n",
    "We also clone a support repository created to supply this notebook with all the annotations alredy converted in the yolov5 notation (converting the annotation in the notebook would be an unneccessary extra step),\n",
    "and the HandsOverFace dataset alredy extracted and cleared from images used in the provided evaluation dataset.\n",
    "We chose to upload HandsOverFace into a repository not for the fact that is easier, but because it was not possible for us to unzip it in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-07-28T08:58:26.938630Z",
     "iopub.status.busy": "2022-07-28T08:58:26.937754Z",
     "iopub.status.idle": "2022-07-28T08:59:41.032740Z",
     "shell.execute_reply": "2022-07-28T08:59:41.031947Z",
     "shell.execute_reply.started": "2022-07-28T08:58:26.938595Z"
    },
    "id": "wcT8I0hNBL9Y",
    "outputId": "77309bac-0b03-4852-ab38-6cee53d4454d"
   },
   "outputs": [],
   "source": [
    "# check if datasets have been downloaded: download it otherwise\n",
    "\n",
    "# First we import the oxford dataset\n",
    "oxford_path = \"hand_dataset.tar.gz\"\n",
    "if not(os.path.exists(oxford_path)):\n",
    "    response = requests.get(\"https://www.robots.ox.ac.uk/~vgg/data/hands/downloads/hand_dataset.tar.gz\")\n",
    "    open(oxford_path, \"wb\").write(response.content)\n",
    "\n",
    "# Then the egohands dataset\n",
    "egohands_path = 'egohands_data.zip'\n",
    "if not(os.path.exists(egohands_path)):\n",
    "  response = requests.get('http://vision.soic.indiana.edu/egohands_files/egohands_data.zip')\n",
    "  open(egohands_path, 'wb').write(response.content)\n",
    "\n",
    "# And finally we import the hands_over_face dataset, plus all the labels we previously converted\n",
    "repo_path = 'dataset_CV'\n",
    "if not(os.path.exists(repo_path)):\n",
    "    !git clone https://github.com/afParadox/dataset_CV.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell we create the dataset directory, where we'll unzip all the files and reorganize them into training, validation and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-07-28T09:00:16.938309Z",
     "iopub.status.busy": "2022-07-28T09:00:16.937342Z",
     "iopub.status.idle": "2022-07-28T09:00:16.944827Z",
     "shell.execute_reply": "2022-07-28T09:00:16.943970Z",
     "shell.execute_reply.started": "2022-07-28T09:00:16.938268Z"
    },
    "id": "i3TXh8qclYBl",
    "outputId": "bf44f494-299e-4132-d09d-162421e575a1"
   },
   "outputs": [],
   "source": [
    "if not(os.path.exists('dataset/')):\n",
    "    !mkdir dataset dataset/images/ dataset/labels/ dataset/egohands\n",
    "    !tar -xvzf hand_dataset.tar.gz -C dataset/\n",
    "    !unzip egohands_data.zip -d dataset/egohands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UKVAbN-oI06E"
   },
   "source": [
    "Now we organize the three datasets that we downloaded into a single one, removing all non-necessary files, and renaming the files when necessary, as in the case of the egohands dataset.\n",
    "The photos included in the evaluation dataset provided by the professor get removed from the dataset used in these cells.\n",
    "In the case of the egohands dataset we also get rid of the whole folders where the photos from the evaluation dataset have been taken. From the total of 48 subfolders in the dataset, only 39 are been used for the training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set as final_path the directory dataset/images/ since all images of the datasets will be moved there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-28T09:00:22.330504Z",
     "iopub.status.busy": "2022-07-28T09:00:22.330144Z",
     "iopub.status.idle": "2022-07-28T09:00:22.334706Z",
     "shell.execute_reply": "2022-07-28T09:00:22.333923Z",
     "shell.execute_reply.started": "2022-07-28T09:00:22.330479Z"
    },
    "id": "PmZcBnLmHYXV"
   },
   "outputs": [],
   "source": [
    "final_path = 'dataset/images/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of the problematic names of the photos of the EgoHands dataset we are forced to rename them all. For every folder we start naming the files from a multiple of 1000.\n",
    "We are also careful to just move the folders that don't include an image that is used in the evaluation dataset provided by the professor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-07-28T09:00:24.438225Z",
     "iopub.status.busy": "2022-07-28T09:00:24.437839Z",
     "iopub.status.idle": "2022-07-28T09:00:25.105060Z",
     "shell.execute_reply": "2022-07-28T09:00:25.103939Z",
     "shell.execute_reply.started": "2022-07-28T09:00:24.438198Z"
    },
    "id": "Q3KTe2WnrdD3",
    "outputId": "babd1bfa-e572-4d11-b4ad-f018a253ab3f"
   },
   "outputs": [],
   "source": [
    "# egohands\n",
    "path = 'dataset/egohands/_LABELLED_SAMPLES/CARDS_COURTYARD_B_T/'\n",
    "counter = 1000\n",
    "for file in sorted(glob.glob(path + '*.jpg')):\n",
    "  new_name = path + str(counter) + '.jpg'\n",
    "  print(file + ' -> ' + new_name)\n",
    "  os.rename(file, final_path + str(counter) + '.jpg')\n",
    "  counter += 1\n",
    "\n",
    "path = 'dataset/egohands/_LABELLED_SAMPLES/CARDS_COURTYARD_H_S/'\n",
    "counter = 2000\n",
    "for file in sorted(glob.glob(path + '*.jpg')):\n",
    "  new_name = path + str(counter) + '.jpg'\n",
    "  print(file + ' -> ' + new_name)\n",
    "  os.rename(file, final_path + str(counter) + '.jpg')\n",
    "  counter += 1\n",
    "\n",
    "path = 'dataset/egohands/_LABELLED_SAMPLES/CARDS_COURTYARD_S_H/'\n",
    "counter = 4000\n",
    "for file in sorted(glob.glob(path + '*.jpg')):\n",
    "  new_name = path + str(counter) + '.jpg'\n",
    "  print(file + ' -> ' + new_name)\n",
    "  os.rename(file, final_path + str(counter) + '.jpg')\n",
    "  counter += 1\n",
    "\n",
    "path = 'dataset/egohands/_LABELLED_SAMPLES/CARDS_COURTYARD_T_B/'\n",
    "counter = 3000\n",
    "for file in sorted(glob.glob(path + '*.jpg')):\n",
    "  new_name = path + str(counter) + '.jpg'\n",
    "  print(file + ' -> ' + new_name)\n",
    "  os.rename(file, final_path + str(counter) + '.jpg')\n",
    "  counter += 1\n",
    "\n",
    "path = 'dataset/egohands/_LABELLED_SAMPLES/CARDS_LIVINGROOM_H_S/'\n",
    "counter = 5000\n",
    "for file in sorted(glob.glob(path + '*.jpg')):\n",
    "  new_name = path + str(counter) + '.jpg'\n",
    "  print(file + ' -> ' + new_name)\n",
    "  os.rename(file, final_path + str(counter) + '.jpg')\n",
    "  counter += 1\n",
    "\n",
    "path = 'dataset/egohands/_LABELLED_SAMPLES/CARDS_LIVINGROOM_S_H/'\n",
    "counter = 6000\n",
    "for file in sorted(glob.glob(path + '*.jpg')):\n",
    "  new_name = path + str(counter) + '.jpg'\n",
    "  print(file + ' -> ' + new_name)\n",
    "  os.rename(file, final_path + str(counter) + '.jpg')\n",
    "  counter += 1\n",
    "\n",
    "path = 'dataset/egohands/_LABELLED_SAMPLES/CARDS_LIVINGROOM_T_B/'\n",
    "counter = 7000\n",
    "for file in sorted(glob.glob(path + '*.jpg')):\n",
    "  new_name = path + str(counter) + '.jpg'\n",
    "  print(file + ' -> ' + new_name)\n",
    "  os.rename(file, final_path + str(counter) + '.jpg')\n",
    "  counter += 1\n",
    "\n",
    "path = 'dataset/egohands/_LABELLED_SAMPLES/CARDS_OFFICE_S_B/'\n",
    "counter = 8000\n",
    "for file in sorted(glob.glob(path + '*.jpg')):\n",
    "  new_name = path + str(counter) + '.jpg'\n",
    "  print(file + ' -> ' + new_name)\n",
    "  os.rename(file, final_path + str(counter) + '.jpg')\n",
    "  counter += 1\n",
    "\n",
    "path = 'dataset/egohands/_LABELLED_SAMPLES/CARDS_OFFICE_T_H/'\n",
    "counter = 9000\n",
    "for file in sorted(glob.glob(path + '*.jpg')):\n",
    "  new_name = path + str(counter) + '.jpg'\n",
    "  print(file + ' -> ' + new_name)\n",
    "  os.rename(file, final_path + str(counter) + '.jpg')\n",
    "  counter += 1\n",
    "\n",
    "path = 'dataset/egohands/_LABELLED_SAMPLES/CHESS_COURTYARD_H_S/'\n",
    "counter = 10000\n",
    "for file in sorted(glob.glob(path + '*.jpg')):\n",
    "  new_name = path + str(counter) + '.jpg'\n",
    "  print(file + ' -> ' + new_name)\n",
    "  os.rename(file, final_path + str(counter) + '.jpg')\n",
    "  counter += 1\n",
    "\n",
    "path = 'dataset/egohands/_LABELLED_SAMPLES/CHESS_COURTYARD_S_H/'\n",
    "counter = 11000\n",
    "for file in sorted(glob.glob(path + '*.jpg')):\n",
    "  new_name = path + str(counter) + '.jpg'\n",
    "  print(file + ' -> ' + new_name)\n",
    "  os.rename(file, final_path + str(counter) + '.jpg')\n",
    "  counter += 1\n",
    "\n",
    "path = 'dataset/egohands/_LABELLED_SAMPLES/CHESS_COURTYARD_T_B/'\n",
    "counter = 12000\n",
    "for file in sorted(glob.glob(path + '*.jpg')):\n",
    "  new_name = path + str(counter) + '.jpg'\n",
    "  print(file + ' -> ' + new_name)\n",
    "  os.rename(file, final_path + str(counter) + '.jpg')\n",
    "  counter += 1\n",
    "\n",
    "path = 'dataset/egohands/_LABELLED_SAMPLES/CHESS_LIVINGROOM_B_S/'\n",
    "counter = 13000\n",
    "for file in sorted(glob.glob(path + '*.jpg')):\n",
    "  new_name = path + str(counter) + '.jpg'\n",
    "  print(file + ' -> ' + new_name)\n",
    "  os.rename(file, final_path + str(counter) + '.jpg')\n",
    "  counter += 1\n",
    "\n",
    "path = 'dataset/egohands/_LABELLED_SAMPLES/CHESS_LIVINGROOM_H_T/'\n",
    "counter = 14000\n",
    "for file in sorted(glob.glob(path + '*.jpg')):\n",
    "  new_name = path + str(counter) + '.jpg'\n",
    "  print(file + ' -> ' + new_name)\n",
    "  os.rename(file, final_path + str(counter) + '.jpg')\n",
    "  counter += 1\n",
    "\n",
    "path = 'dataset/egohands/_LABELLED_SAMPLES/CHESS_LIVINGROOM_S_B/'\n",
    "counter = 15000\n",
    "for file in sorted(glob.glob(path + '*.jpg')):\n",
    "  new_name = path + str(counter) + '.jpg'\n",
    "  print(file + ' -> ' + new_name)\n",
    "  os.rename(file, final_path + str(counter) + '.jpg')\n",
    "  counter += 1\n",
    "\n",
    "path = 'dataset/egohands/_LABELLED_SAMPLES/CHESS_LIVINGROOM_T_H/'\n",
    "counter = 16000\n",
    "for file in sorted(glob.glob(path + '*.jpg')):\n",
    "  new_name = path + str(counter) + '.jpg'\n",
    "  print(file + ' -> ' + new_name)\n",
    "  os.rename(file, final_path + str(counter) + '.jpg')\n",
    "  counter += 1\n",
    "\n",
    "path = 'dataset/egohands/_LABELLED_SAMPLES/CHESS_OFFICE_H_T/'\n",
    "counter = 17000\n",
    "for file in sorted(glob.glob(path + '*.jpg')):\n",
    "  new_name = path + str(counter) + '.jpg'\n",
    "  print(file + ' -> ' + new_name)\n",
    "  os.rename(file, final_path + str(counter) + '.jpg')\n",
    "  counter += 1\n",
    "\n",
    "path = 'dataset/egohands/_LABELLED_SAMPLES/CHESS_OFFICE_S_B/'\n",
    "counter = 18000\n",
    "for file in sorted(glob.glob(path + '*.jpg')):\n",
    "  new_name = path + str(counter) + '.jpg'\n",
    "  print(file + ' -> ' + new_name)\n",
    "  os.rename(file, final_path + str(counter) + '.jpg')\n",
    "  counter += 1\n",
    "\n",
    "path = 'dataset/egohands/_LABELLED_SAMPLES/CHESS_OFFICE_T_H/'\n",
    "counter = 19000\n",
    "for file in sorted(glob.glob(path + '*.jpg')):\n",
    "  new_name = path + str(counter) + '.jpg'\n",
    "  print(file + ' -> ' + new_name)\n",
    "  os.rename(file, final_path + str(counter) + '.jpg')\n",
    "  counter += 1\n",
    "\n",
    "path = 'dataset/egohands/_LABELLED_SAMPLES/JENGA_COURTYARD_H_B/'\n",
    "counter = 20000\n",
    "for file in sorted(glob.glob(path + '*.jpg')):\n",
    "  new_name = path + str(counter) + '.jpg'\n",
    "  print(file + ' -> ' + new_name)\n",
    "  os.rename(file, final_path + str(counter) + '.jpg')\n",
    "  counter += 1\n",
    "\n",
    "path = 'dataset/egohands/_LABELLED_SAMPLES/JENGA_COURTYARD_S_T/'\n",
    "counter = 21000\n",
    "for file in sorted(glob.glob(path + '*.jpg')):\n",
    "  new_name = path + str(counter) + '.jpg'\n",
    "  print(file + ' -> ' + new_name)\n",
    "  os.rename(file, final_path + str(counter) + '.jpg')\n",
    "  counter += 1\n",
    "\n",
    "path = 'dataset/egohands/_LABELLED_SAMPLES/JENGA_COURTYARD_T_S/'\n",
    "counter = 22000\n",
    "for file in sorted(glob.glob(path + '*.jpg')):\n",
    "  new_name = path + str(counter) + '.jpg'\n",
    "  print(file + ' -> ' + new_name)\n",
    "  os.rename(file, final_path + str(counter) + '.jpg')\n",
    "  counter += 1\n",
    "\n",
    "path = 'dataset/egohands/_LABELLED_SAMPLES/JENGA_LIVINGROOM_B_H/'\n",
    "counter = 23000\n",
    "for file in sorted(glob.glob(path + '*.jpg')):\n",
    "  new_name = path + str(counter) + '.jpg'\n",
    "  print(file + ' -> ' + new_name)\n",
    "  os.rename(file, final_path + str(counter) + '.jpg')\n",
    "  counter += 1\n",
    "\n",
    "path = 'dataset/egohands/_LABELLED_SAMPLES/JENGA_LIVINGROOM_S_T/'\n",
    "counter = 24000\n",
    "for file in sorted(glob.glob(path + '*.jpg')):\n",
    "  new_name = path + str(counter) + '.jpg'\n",
    "  print(file + ' -> ' + new_name)\n",
    "  os.rename(file, final_path + str(counter) + '.jpg')\n",
    "  counter += 1\n",
    "\n",
    "path = 'dataset/egohands/_LABELLED_SAMPLES/JENGA_LIVINGROOM_T_S/'\n",
    "counter = 25000\n",
    "for file in sorted(glob.glob(path + '*.jpg')):\n",
    "  new_name = path + str(counter) + '.jpg'\n",
    "  print(file + ' -> ' + new_name)\n",
    "  os.rename(file, final_path + str(counter) + '.jpg')\n",
    "  counter += 1\n",
    "\n",
    "path = 'dataset/egohands/_LABELLED_SAMPLES/JENGA_OFFICE_B_S/'\n",
    "counter = 26000\n",
    "for file in sorted(glob.glob(path + '*.jpg')):\n",
    "  new_name = path + str(counter) + '.jpg'\n",
    "  print(file + ' -> ' + new_name)\n",
    "  os.rename(file, final_path + str(counter) + '.jpg')\n",
    "  counter += 1\n",
    "\n",
    "path = 'dataset/egohands/_LABELLED_SAMPLES/JENGA_OFFICE_H_T/'\n",
    "counter = 27000\n",
    "for file in sorted(glob.glob(path + '*.jpg')):\n",
    "  new_name = path + str(counter) + '.jpg'\n",
    "  print(file + ' -> ' + new_name)\n",
    "  os.rename(file, final_path + str(counter) + '.jpg')\n",
    "  counter += 1\n",
    "\n",
    "path = 'dataset/egohands/_LABELLED_SAMPLES/JENGA_OFFICE_S_B/'\n",
    "counter = 28000\n",
    "for file in sorted(glob.glob(path + '*.jpg')):\n",
    "  new_name = path + str(counter) + '.jpg'\n",
    "  print(file + ' -> ' + new_name)\n",
    "  os.rename(file, final_path + str(counter) + '.jpg')\n",
    "  counter += 1\n",
    "\n",
    "path = 'dataset/egohands/_LABELLED_SAMPLES/JENGA_OFFICE_T_H/'\n",
    "counter = 29000\n",
    "for file in sorted(glob.glob(path + '*.jpg')):\n",
    "  new_name = path + str(counter) + '.jpg'\n",
    "  print(file + ' -> ' + new_name)\n",
    "  os.rename(file, final_path + str(counter) + '.jpg')\n",
    "  counter += 1\n",
    "\n",
    "path = 'dataset/egohands/_LABELLED_SAMPLES/PUZZLE_COURTYARD_H_T/'\n",
    "counter = 30000\n",
    "for file in sorted(glob.glob(path + '*.jpg')):\n",
    "  new_name = path + str(counter) + '.jpg'\n",
    "  print(file + ' -> ' + new_name)\n",
    "  os.rename(file, final_path + str(counter) + '.jpg')\n",
    "  counter += 1\n",
    "\n",
    "path = 'dataset/egohands/_LABELLED_SAMPLES/PUZZLE_COURTYARD_S_B/'\n",
    "counter = 31000\n",
    "for file in sorted(glob.glob(path + '*.jpg')):\n",
    "  new_name = path + str(counter) + '.jpg'\n",
    "  print(file + ' -> ' + new_name)\n",
    "  os.rename(file, final_path + str(counter) + '.jpg')\n",
    "  counter += 1\n",
    "\n",
    "path = 'dataset/egohands/_LABELLED_SAMPLES/PUZZLE_COURTYARD_T_H/'\n",
    "counter = 32000\n",
    "for file in sorted(glob.glob(path + '*.jpg')):\n",
    "  new_name = path + str(counter) + '.jpg'\n",
    "  print(file + ' -> ' + new_name)\n",
    "  os.rename(file, final_path + str(counter) + '.jpg')\n",
    "  counter += 1\n",
    "\n",
    "path = 'dataset/egohands/_LABELLED_SAMPLES/PUZZLE_LIVINGROOM_B_T/'\n",
    "counter = 33000\n",
    "for file in sorted(glob.glob(path + '*.jpg')):\n",
    "  new_name = path + str(counter) + '.jpg'\n",
    "  print(file + ' -> ' + new_name)\n",
    "  os.rename(file, final_path + str(counter) + '.jpg')\n",
    "  counter += 1\n",
    "\n",
    "path = 'dataset/egohands/_LABELLED_SAMPLES/PUZZLE_LIVINGROOM_H_S/'\n",
    "counter = 34000\n",
    "for file in sorted(glob.glob(path + '*.jpg')):\n",
    "  new_name = path + str(counter) + '.jpg'\n",
    "  print(file + ' -> ' + new_name)\n",
    "  os.rename(file, final_path + str(counter) + '.jpg')\n",
    "  counter += 1\n",
    "\n",
    "path = 'dataset/egohands/_LABELLED_SAMPLES/PUZZLE_LIVINGROOM_S_H/'\n",
    "counter = 35000\n",
    "for file in sorted(glob.glob(path + '*.jpg')):\n",
    "  new_name = path + str(counter) + '.jpg'\n",
    "  print(file + ' -> ' + new_name)\n",
    "  os.rename(file, final_path + str(counter) + '.jpg')\n",
    "  counter += 1\n",
    "\n",
    "path = 'dataset/egohands/_LABELLED_SAMPLES/PUZZLE_LIVINGROOM_T_B/'\n",
    "counter = 36000\n",
    "for file in sorted(glob.glob(path + '*.jpg')):\n",
    "  new_name = path + str(counter) + '.jpg'\n",
    "  print(file + ' -> ' + new_name)\n",
    "  os.rename(file, final_path + str(counter) + '.jpg')\n",
    "  counter += 1\n",
    "\n",
    "path = 'dataset/egohands/_LABELLED_SAMPLES/PUZZLE_OFFICE_H_B/'\n",
    "counter = 37000\n",
    "for file in sorted(glob.glob(path + '*.jpg')):\n",
    "  new_name = path + str(counter) + '.jpg'\n",
    "  print(file + ' -> ' + new_name)\n",
    "  os.rename(file, final_path + str(counter) + '.jpg')\n",
    "  counter += 1\n",
    "\n",
    "path = 'dataset/egohands/_LABELLED_SAMPLES/PUZZLE_OFFICE_S_T/'\n",
    "counter = 38000\n",
    "for file in sorted(glob.glob(path + '*.jpg')):\n",
    "  new_name = path + str(counter) + '.jpg'\n",
    "  print(file + ' -> ' + new_name)\n",
    "  os.rename(file, final_path + str(counter) + '.jpg')\n",
    "  counter += 1\n",
    "\n",
    "path = 'dataset/egohands/_LABELLED_SAMPLES/PUZZLE_OFFICE_T_S/'\n",
    "counter = 39000\n",
    "for file in sorted(glob.glob(path + '*.jpg')):\n",
    "  new_name = path + str(counter) + '.jpg'\n",
    "  print(file + ' -> ' + new_name)\n",
    "  os.rename(file, final_path + str(counter) + '.jpg')\n",
    "  counter += 1\n",
    "\n",
    "!rm -rf dataset/egohands/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of the oxford dataset we don't have to change every image name, but only the ones in the test_data subdirectory, since their names conflict with other files in the dataset.\n",
    "Also, we have to check each folder for the extra files that we don't need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-27T15:15:06.535633Z",
     "iopub.status.busy": "2022-07-27T15:15:06.534895Z",
     "iopub.status.idle": "2022-07-27T15:15:36.050554Z",
     "shell.execute_reply": "2022-07-27T15:15:36.049592Z",
     "shell.execute_reply.started": "2022-07-27T15:15:06.535557Z"
    },
    "id": "LsFGZ_jaAvOe"
   },
   "outputs": [],
   "source": [
    "# oxford \n",
    "path = 'dataset/hand_dataset/training_dataset/training_data/images/'\n",
    "for file in os.listdir(path):\n",
    "  if file == '._.DS_Store' or file == '.DS_Store': continue\n",
    "  os.rename(path + file, final_path + file)\n",
    "\n",
    "path = 'dataset/hand_dataset/validation_dataset/validation_data/images/'\n",
    "for file in os.listdir(path):\n",
    "  if file == '._.DS_Store' or file == '.DS_Store': continue\n",
    "  os.rename(path + file, final_path + file)\n",
    "\n",
    "path = 'dataset/hand_dataset/test_dataset/test_data/images/'\n",
    "counter = 40000\n",
    "for file in sorted(glob.glob(path + '*.jpg')):\n",
    "  if file == '._.DS_Store' or file == '.DS_Store': continue\n",
    "  os.rename(file, final_path + str(counter) + '.jpg')\n",
    "  counter += 1\n",
    "\n",
    "!rm -rf dataset/hand_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of the HandsOverFace dataset we just import it from the support repository and move it into the images folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the last step of this organization we also move all the annotations from the photos into the dataset/labels/ directory,\n",
    "to have a easier to understand structure of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-27T15:15:36.051910Z",
     "iopub.status.busy": "2022-07-27T15:15:36.051640Z",
     "iopub.status.idle": "2022-07-27T15:15:50.364201Z",
     "shell.execute_reply": "2022-07-27T15:15:50.362888Z",
     "shell.execute_reply.started": "2022-07-27T15:15:36.051883Z"
    },
    "id": "-X2WtIRLZipP"
   },
   "outputs": [],
   "source": [
    "# Finally we move the labels we imported to the labels folder\n",
    "final_path = 'dataset/labels/'\n",
    "initial_path = 'dataset_CV/labels/'\n",
    "for file in os.listdir(initial_path):\n",
    "  os.rename(initial_path + file, final_path + file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HAV_Yq717VeD"
   },
   "source": [
    "The next cell serves the purpose of checking that we moved all the data correctly.\n",
    "First we check that we have the same number of images and annotation files by printing the number of files in each one,\n",
    "and if an annotation file is missing then we print the name of its respective image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-07-28T09:02:01.188829Z",
     "iopub.status.busy": "2022-07-28T09:02:01.187840Z"
    },
    "id": "5jHr2pyOa_XZ",
    "outputId": "81cb87a9-4874-4aba-889f-113eee10e6db"
   },
   "outputs": [],
   "source": [
    "print(len(os.listdir('dataset/images/')))\n",
    "print(len(os.listdir('dataset/labels/')))\n",
    "\n",
    "path_1 = 'dataset/images/'\n",
    "path_2 = 'dataset/labels/'\n",
    "\n",
    "for file in os.listdir(path_1):\n",
    "    txt_name = file[:-4] + '.txt'\n",
    "    if txt_name not in os.listdir(path_2):\n",
    "        print(txt_name + ' missing')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1W9gBW91YiX4"
   },
   "source": [
    "Now we want to create the validation and test set. We just take 1000 random samples for validation and 800 for test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-07-27T15:16:34.123691Z",
     "iopub.status.busy": "2022-07-27T15:16:34.123431Z",
     "iopub.status.idle": "2022-07-27T15:33:37.261588Z",
     "shell.execute_reply": "2022-07-27T15:33:37.260701Z",
     "shell.execute_reply.started": "2022-07-27T15:16:34.123668Z"
    },
    "id": "29o9yTMLXGiC",
    "outputId": "71ad81af-882f-4cb8-c54c-2009d082d26c"
   },
   "outputs": [],
   "source": [
    "!mkdir dataset/validation/ dataset/validation/images/ dataset/validation/labels/\n",
    "!mkdir dataset/test/ dataset/test/images dataset/test/labels\n",
    "\n",
    "random.seed(10000)\n",
    "\n",
    "images_path = 'dataset/images/'\n",
    "labels_path = 'dataset/labels/'\n",
    "validation_images = 'dataset/validation/images/'\n",
    "validation_labels = 'dataset/validation/labels/'\n",
    "test_images = 'dataset/test/images/'\n",
    "test_labels = 'dataset/test/labels/'\n",
    "\n",
    "# Here we populate the validation set\n",
    "for i in range(1000):\n",
    "  list = sorted(os.listdir(images_path))\n",
    "  n = random.randint(0, len(list) - 1)\n",
    "  #print(list[n][:-4] + ' -> validation')\n",
    "  os.rename(images_path + list[n], validation_images + list[n])\n",
    "  os.rename(labels_path + list[n][:-4] + '.txt', validation_labels + list[n][:-4] + '.txt')\n",
    "\n",
    "# Here we populate the test set\n",
    "\n",
    "\n",
    "for i in range(800):\n",
    "  list = sorted(os.listdir(images_path))\n",
    "  n = random.randint(0, len(list) - 1)\n",
    "  #print(list[n][:-4] + ' -> test')\n",
    "  os.rename(images_path + list[n], test_images + list[n])\n",
    "  os.rename(labels_path + list[n][:-4] + '.txt', test_labels + list[n][:-4] + '.txt')\n",
    "  \n",
    "print(len(os.listdir(validation_images)))\n",
    "print(len(os.listdir(validation_labels)))\n",
    "print(len(os.listdir(test_images)))\n",
    "print(len(os.listdir(test_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-27T15:41:02.762559Z",
     "iopub.status.busy": "2022-07-27T15:41:02.761752Z",
     "iopub.status.idle": "2022-07-27T15:41:02.778158Z",
     "shell.execute_reply": "2022-07-27T15:41:02.777344Z",
     "shell.execute_reply.started": "2022-07-27T15:41:02.762528Z"
    },
    "id": "5_Zx2Kz8Au3a"
   },
   "outputs": [],
   "source": [
    "# hands over face\n",
    "path = 'dataset_CV/hands_over_face/'\n",
    "for file in os.listdir(path):\n",
    "  os.rename(path + file, final_path + file)\n",
    "\n",
    "!rm -rf dataset_CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jhgi_L4LBL9b"
   },
   "source": [
    "### 3) Check conversions\n",
    "Now to check if the conversion result is correct by visualizing random samples for each subset of the dataset and drawing the converted bounding box(es) onto it.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "execution": {
     "iopub.status.busy": "2022-07-27T15:33:37.743554Z",
     "iopub.status.idle": "2022-07-27T15:33:37.743818Z"
    },
    "id": "AE95IYHfBL9c",
    "outputId": "238f24dc-c397-487b-9d68-bf251208884f"
   },
   "outputs": [],
   "source": [
    "datasets_extr = [\"dataset/\",\"dataset/test/\", \"dataset/validation/\"]\n",
    "\n",
    "for dir_path in datasets_extr:\n",
    "    # randomly select an image\n",
    "    rnd_img = random.choice(os.listdir(dir_path + \"images/\"))\n",
    "    print(rnd_img)\n",
    "\n",
    "    # open the image\n",
    "    img = Image.open(dir_path + \"images/\" + rnd_img)\n",
    "\n",
    "    # create figure and axes\n",
    "    fig, ax = plt.subplots(dpi=163)\n",
    "\n",
    "    # display the image\n",
    "    ax.imshow(img)\n",
    "\n",
    "    #covert line string into ndarray\n",
    "    bbox_yolo_coords = []\n",
    "    with open(dir_path + \"labels/\" + rnd_img[:len(rnd_img)-4] + \".txt\") as txt:\n",
    "\n",
    "        lines = txt.read().splitlines()\n",
    "        for line in lines:\n",
    "            bbox_yolo_coords.append(np.fromstring(line[1:], dtype=float, sep=' ', count=4))\n",
    "\n",
    "    # de-normalize coordinates and draw bbox onto img\n",
    "    for box in bbox_yolo_coords:\n",
    "        box[0] *= float(img.width)\n",
    "        box[2] *= float(img.width)\n",
    "        box[1] *= float(img.height)\n",
    "        box[3] *= float(img.height)\n",
    "        ax.add_patch(patches.Rectangle((box[0]-box[2]/2., box[1]-box[3]/2.), width=box[2], height=box[3], linewidth=1, edgecolor='r', facecolor='none'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bIn6W-0mBL9d"
   },
   "source": [
    "### 4) Last steps before training\n",
    "Now we need to setup last things to train the yolo model. We will follow the following steps:\n",
    "- Copy images and labels into a directory system suitable to yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-27T15:33:37.744623Z",
     "iopub.status.idle": "2022-07-27T15:33:37.744874Z"
    },
    "id": "GXoKsy9eBL9e"
   },
   "outputs": [],
   "source": [
    "dirs = [\"./images/\", \"./labels/\", \"./images/train/\", \"./labels/train/\", \"./images/val/\", \"./labels/val/\", \"./images/test/\", \"./labels/test/\"]\n",
    "for dir_ in dirs:\n",
    "    if not os.path.exists(dir_):\n",
    "        os.mkdir(dir_)\n",
    "\n",
    "# move dataset into directories \"images\" and \"labels\" which are located in same position as the notebook\n",
    "subsets = [\"train/\", \"val/\", \"test/\"]\n",
    "for i in range(3):\n",
    "    for img_name in os.listdir(datasets_extr[i] + \"images/\"):\n",
    "        old_img_path = datasets_extr[i] + \"images/\" + img_name\n",
    "        old_lbl_path = datasets_extr[i] + \"labels/\" + img_name[:len(img_name)-3] + \"txt\"\n",
    "        new_img_path = dirs[0] + subsets[i] + img_name\n",
    "        new_lbl_path = dirs[1] + subsets[i] + img_name[:len(img_name)-3] + \"txt\"\n",
    "\n",
    "        # copy img if it's not already there\n",
    "        if not os.path.exists(new_img_path):\n",
    "            shutil.copyfile(old_img_path, new_img_path)\n",
    "        if not os.path.exists(new_lbl_path):\n",
    "            shutil.copyfile(old_lbl_path, new_lbl_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UL7SM6QOBL9e"
   },
   "source": [
    "- Create dataset location _yaml_ file (In our case move the premade one into the right directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.status.busy": "2022-07-27T15:33:37.745433Z",
     "iopub.status.idle": "2022-07-27T15:33:37.745678Z"
    },
    "id": "ibgG7CpRBL9f",
    "outputId": "ef9380ee-c6fe-4375-fdd5-fd997974de49"
   },
   "outputs": [],
   "source": [
    "# move data.yaml\n",
    "new_data_yaml = \"./yolov5/data/hand_data.yaml\"\n",
    "if os.path.exists(new_data_yaml):\n",
    "    os.remove(new_data_yaml)\n",
    "shutil.copyfile(\"./hand_data.yaml\", new_data_yaml)\n",
    "\n",
    "\n",
    "print(\"------------------ hand_data.yaml ---------------------\")\n",
    "with open(new_data_yaml) as f:\n",
    "    lines = f.read().splitlines()\n",
    "    for line in lines:\n",
    "        print(\"\\t\" + line)\n",
    "print(\"-------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I7CFnw10BL9f"
   },
   "source": [
    "- Setup hyperparameters file, which will contain all usual parameters used when training a neural network (Same as before, we will move the premade one into the right directory)<br>\n",
    "  We are just going to use the default one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.status.busy": "2022-07-27T15:33:37.746267Z",
     "iopub.status.idle": "2022-07-27T15:33:37.746514Z"
    },
    "id": "QmcyMmJwBL9f",
    "outputId": "cdc24859-c890-4b3d-ded9-572f6e36e430"
   },
   "outputs": [],
   "source": [
    "hyperparams_yaml = \"./yolov5/data/hyps/hyp.scratch-med.yaml\"\n",
    "print(\"-------------------------------------------------- hyp.scratch-med.yaml -----------------------------------------------------\")\n",
    "with open(hyperparams_yaml) as f:\n",
    "    lines = f.read().splitlines()\n",
    "    for line in lines:\n",
    "        print(\"\\t\" + line)\n",
    "print(\"-----------------------------------------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n07DX8c2BL9f"
   },
   "source": [
    "- A custom network architecture can also be specified by specifing with _-cfg_ argument the custom network architecture file.<br>\n",
    "  Below there is and example taken from a default yolo network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.status.busy": "2022-07-27T15:33:37.747161Z",
     "iopub.status.idle": "2022-07-27T15:33:37.747468Z"
    },
    "id": "iMT3hOQWBL9f",
    "outputId": "f3aea3e6-2b3e-4790-c296-b8031b665043"
   },
   "outputs": [],
   "source": [
    "net_architecture_yaml = \"./yolov5/models/yolov5l.yaml\"\n",
    "print(\"------------------------------------------------------ yolov5m.yaml --------------------------------------------------------\")\n",
    "with open(net_architecture_yaml) as f:\n",
    "    lines = f.read().splitlines()\n",
    "    for line in lines:\n",
    "        print(\"\\t\" + line)\n",
    "print(\"-----------------------------------------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aGVz491nBL9g"
   },
   "source": [
    "### 5) Training the yolo model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.status.busy": "2022-07-27T15:33:37.748418Z",
     "iopub.status.idle": "2022-07-27T15:33:37.748666Z"
    },
    "id": "ntK4JqorBL9g",
    "outputId": "b3c01581-aed0-4321-904d-fdcc251165cd"
   },
   "outputs": [],
   "source": [
    "# 313 could be a good batch size (1,13,313,4069)\n",
    "#!cd yolov5\n",
    "!python yolov5/train.py --img 640 --cfg yolov5s.yaml --hyp hyp.scratch-med.yaml --batch 20 --epochs 60 --data hand_data.yaml --weights ' ' --workers 8 --name yolo_hand_localization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyQ7-4pMhlJb"
   },
   "source": [
    "Now to download the results: first create a zip file, then download it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-27T15:33:37.749301Z",
     "iopub.status.idle": "2022-07-27T15:33:37.749546Z"
    },
    "id": "wig2WSjehrDw"
   },
   "outputs": [],
   "source": [
    "!zip -r ./training_result_runs.zip ./yolov5/runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "yolov5_hand_localization.v2.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
